{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d460598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"filtered_lowcap_stocks.json\", \"r\") as f:\n",
    "    filtered = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63953379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    with open(\"../.env\") as f:\n",
    "        lines = f.readlines()\n",
    "        env = {}\n",
    "        for line in lines:\n",
    "            if \"=\" in line:\n",
    "                k, v = line.strip().replace('\"', '').split(\"=\", 1)\n",
    "                env[k] = v\n",
    "    return env\n",
    "env = get_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66eddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def chunked(xs, n):\n",
    "    for i in range(0, len(xs), n):\n",
    "        yield xs[i:i+n]\n",
    "\n",
    "def alpaca_liq_vol_screen(\n",
    "    symbols: list[str],\n",
    "    auth: dict,\n",
    "    days: int = 180,\n",
    "    bar_timeframe: str = \"1Day\",\n",
    "    symbols_per_call: int = 200,\n",
    "    sleep_s: float = 0.25,\n",
    "    adv_min: float = 150_000.0,\n",
    "    adv_max: float = 20_000_000.0,   # \"too liquid / hedge-fund friendly\" cutoff\n",
    "    vol_window_short: int = 20,\n",
    "    vol_window_long: int = 60,\n",
    "    big_move: float = 0.15,          # 15% daily move threshold\n",
    "    min_days_required: int = 90,\n",
    ") -> pd.DataFrame:\n",
    "    base = (auth.get(\"ALPACA_DATA_BASE_URL\") or \"https://data.alpaca.markets\").rstrip(\"/\")\n",
    "    key_id = (auth.get(\"ALPACA_KEY\") or \"\").strip().strip('\"').strip(\"'\")\n",
    "    secret = (auth.get(\"ALPACA_SECRET\") or \"\").strip().strip('\"').strip(\"'\")\n",
    "    if not key_id or not secret:\n",
    "        raise ValueError(\"Missing ALPACA_KEY / ALPACA_SECRET in auth\")\n",
    "\n",
    "    headers = {\"APCA-API-KEY-ID\": key_id, \"APCA-API-SECRET-KEY\": secret}\n",
    "\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for batch in chunked([s.upper() for s in symbols], symbols_per_call):\n",
    "        params = {\n",
    "            \"symbols\": \",\".join(batch),\n",
    "            \"timeframe\": bar_timeframe,\n",
    "            \"start\": start.isoformat(),\n",
    "            \"end\": end.isoformat(),\n",
    "            \"adjustment\": \"all\",\n",
    "            \"feed\": auth.get(\"ALPACA_DATA_FEED\", \"iex\"),\n",
    "            \"limit\": 10000,\n",
    "        }\n",
    "        r = requests.get(f\"{base}/v2/stocks/bars\", headers=headers, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        bars_by_symbol = data.get(\"bars\", {})\n",
    "        for sym, bars in bars_by_symbol.items():\n",
    "            if not bars:\n",
    "                continue\n",
    "            df = pd.DataFrame(bars)\n",
    "            # Alpaca fields: t,o,h,l,c,v,n,vw (t timestamp)\n",
    "            if \"t\" not in df.columns or \"c\" not in df.columns or \"v\" not in df.columns:\n",
    "                continue\n",
    "            df[\"t\"] = pd.to_datetime(df[\"t\"], utc=True)\n",
    "            df = df.sort_values(\"t\")\n",
    "            df[\"sym\"] = sym\n",
    "            all_rows.append(df[[\"sym\", \"t\", \"c\", \"v\"]])\n",
    "\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"symbol\",\"n_days\",\"last_close\",\"adv20\",\"adv60\",\"vol20\",\"vol60\",\n",
    "            \"pct_big_moves_60d\",\"max_dd_120d\",\"liq_ok\",\"hf_ok\",\"data_ok\",\"score\"\n",
    "        ])\n",
    "\n",
    "    bars = pd.concat(all_rows, ignore_index=True)\n",
    "    bars = bars.dropna(subset=[\"c\", \"v\"])\n",
    "    bars[\"dvol\"] = bars[\"c\"].astype(float) * bars[\"v\"].astype(float)\n",
    "\n",
    "    out = []\n",
    "    for sym, g in bars.groupby(\"sym\", sort=False):\n",
    "        g = g.sort_values(\"t\")\n",
    "        n = len(g)\n",
    "        if n < min_days_required:\n",
    "            out.append({\"symbol\": sym, \"n_days\": n, \"data_ok\": False})\n",
    "            continue\n",
    "\n",
    "        close = g[\"c\"].astype(float).to_numpy()\n",
    "        dvol = g[\"dvol\"].astype(float).to_numpy()\n",
    "\n",
    "        rets = np.diff(np.log(close))\n",
    "        # align return-based measures to last rows\n",
    "        def roll_std(x, w):\n",
    "            if len(x) < w:\n",
    "                return np.nan\n",
    "            return float(np.std(x[-w:], ddof=1))\n",
    "\n",
    "        vol20 = roll_std(rets, vol_window_short) * math.sqrt(252)\n",
    "        vol60 = roll_std(rets, vol_window_long) * math.sqrt(252)\n",
    "\n",
    "        adv20 = float(np.mean(dvol[-min(vol_window_short, len(dvol)):]))\n",
    "        adv60 = float(np.mean(dvol[-min(vol_window_long, len(dvol)):]))\n",
    "        last_close = float(close[-1])\n",
    "\n",
    "        # big-move frequency over last 60 trading days\n",
    "        last_rets = rets[-min(vol_window_long, len(rets)):]\n",
    "        pct_big = float(np.mean(np.abs(np.expm1(last_rets)) >= big_move)) if len(last_rets) else np.nan\n",
    "\n",
    "        # max drawdown over last 120 trading days\n",
    "        win = min(120, len(close))\n",
    "        px = close[-win:]\n",
    "        peak = np.maximum.accumulate(px)\n",
    "        dd = (px / peak) - 1.0\n",
    "        max_dd = float(dd.min())\n",
    "\n",
    "        liq_ok = (adv20 >= adv_min)\n",
    "        hf_ok = (adv20 <= adv_max)  # if False => \"too liquid / likely crowded\"\n",
    "        data_ok = True\n",
    "\n",
    "        # simple score: prefer liquid-enough but not-too-liquid, penalize extreme vol + jumpiness\n",
    "        # (you can tune weights)\n",
    "        score = 0.0\n",
    "        if data_ok:\n",
    "            # center liquidity around geometric mid of [adv_min, adv_max]\n",
    "            mid = math.sqrt(adv_min * adv_max)\n",
    "            score += -abs(math.log(max(adv20, 1.0) / mid))\n",
    "            if not liq_ok:\n",
    "                score -= 2.0\n",
    "            if not hf_ok:\n",
    "                score -= 1.5\n",
    "            if not np.isnan(vol60):\n",
    "                score -= 0.5 * max(0.0, (vol60 - 0.8))  # penalize >80% ann vol\n",
    "            if not np.isnan(pct_big):\n",
    "                score -= 2.0 * pct_big               # penalize jumpy names\n",
    "            score += 0.25 * max_dd                   # drawdown is negative; bigger drawdown => lower score\n",
    "\n",
    "        out.append({\n",
    "            \"symbol\": sym,\n",
    "            \"n_days\": n,\n",
    "            \"last_close\": last_close,\n",
    "            \"adv20\": adv20,\n",
    "            \"adv60\": adv60,\n",
    "            \"vol20\": vol20,\n",
    "            \"vol60\": vol60,\n",
    "            \"pct_big_moves_60d\": pct_big,\n",
    "            \"max_dd_120d\": max_dd,\n",
    "            \"liq_ok\": liq_ok,\n",
    "            \"hf_ok\": hf_ok,\n",
    "            \"data_ok\": data_ok,\n",
    "            \"score\": score,\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(out)\n",
    "\n",
    "    # Fill missing columns for short-history rows\n",
    "    for col in [\"last_close\",\"adv20\",\"adv60\",\"vol20\",\"vol60\",\"pct_big_moves_60d\",\"max_dd_120d\",\"liq_ok\",\"hf_ok\",\"score\"]:\n",
    "        if col not in df_out.columns:\n",
    "            df_out[col] = np.nan\n",
    "\n",
    "    # Rank: keep only data_ok, then liq_ok, then hf_ok, then score\n",
    "    df_out = df_out.sort_values(\n",
    "        by=[\"data_ok\",\"liq_ok\",\"hf_ok\",\"score\"],\n",
    "        ascending=[False, False, False, False],\n",
    "        kind=\"mergesort\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fde05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = alpaca_liq_vol_screen(\n",
    "    symbols=list(filtered.keys()),   # your 213 symbols\n",
    "    auth=env,\n",
    "    days=365,\n",
    "    adv_min=200_000,\n",
    "    adv_max=20_000_000,\n",
    "    big_move=0.15,\n",
    "    symbols_per_call=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319f155d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>n_days</th>\n",
       "      <th>last_close</th>\n",
       "      <th>adv20</th>\n",
       "      <th>adv60</th>\n",
       "      <th>vol20</th>\n",
       "      <th>vol60</th>\n",
       "      <th>pct_big_moves_60d</th>\n",
       "      <th>max_dd_120d</th>\n",
       "      <th>liq_ok</th>\n",
       "      <th>hf_ok</th>\n",
       "      <th>data_ok</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUST</td>\n",
       "      <td>250</td>\n",
       "      <td>5.840</td>\n",
       "      <td>3.541780e+06</td>\n",
       "      <td>3.134439e+06</td>\n",
       "      <td>0.703097</td>\n",
       "      <td>0.887591</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.759868</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.838578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELME</td>\n",
       "      <td>250</td>\n",
       "      <td>2.870</td>\n",
       "      <td>6.564464e+05</td>\n",
       "      <td>3.963512e+05</td>\n",
       "      <td>0.226579</td>\n",
       "      <td>0.152931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.059595</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.128960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNG</td>\n",
       "      <td>250</td>\n",
       "      <td>11.320</td>\n",
       "      <td>5.708852e+06</td>\n",
       "      <td>4.604550e+06</td>\n",
       "      <td>0.722811</td>\n",
       "      <td>0.622602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.364580</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.140016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPCE</td>\n",
       "      <td>250</td>\n",
       "      <td>3.080</td>\n",
       "      <td>7.050816e+05</td>\n",
       "      <td>5.257106e+05</td>\n",
       "      <td>0.648899</td>\n",
       "      <td>0.805177</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.344156</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.164550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>250</td>\n",
       "      <td>7.520</td>\n",
       "      <td>6.941155e+05</td>\n",
       "      <td>7.997527e+05</td>\n",
       "      <td>1.146521</td>\n",
       "      <td>1.039477</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.475503</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.363545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SITC</td>\n",
       "      <td>250</td>\n",
       "      <td>6.500</td>\n",
       "      <td>5.111240e+05</td>\n",
       "      <td>5.012912e+05</td>\n",
       "      <td>0.190387</td>\n",
       "      <td>0.243997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.183844</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.410251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PTLO</td>\n",
       "      <td>250</td>\n",
       "      <td>5.200</td>\n",
       "      <td>5.536657e+05</td>\n",
       "      <td>6.115804e+05</td>\n",
       "      <td>0.490735</td>\n",
       "      <td>0.505632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.575686</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.428263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RC</td>\n",
       "      <td>250</td>\n",
       "      <td>2.075</td>\n",
       "      <td>5.153672e+05</td>\n",
       "      <td>4.319559e+05</td>\n",
       "      <td>0.419840</td>\n",
       "      <td>0.500689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.536501</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.490148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISSC</td>\n",
       "      <td>250</td>\n",
       "      <td>19.310</td>\n",
       "      <td>5.406963e+05</td>\n",
       "      <td>2.828315e+05</td>\n",
       "      <td>1.197928</td>\n",
       "      <td>0.808118</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.578105</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.523297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FC</td>\n",
       "      <td>250</td>\n",
       "      <td>19.375</td>\n",
       "      <td>4.250869e+05</td>\n",
       "      <td>3.060991e+05</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0.479614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.304369</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.624701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  n_days  last_close         adv20         adv60     vol20     vol60  \\\n",
       "0   DUST     250       5.840  3.541780e+06  3.134439e+06  0.703097  0.887591   \n",
       "1   ELME     250       2.870  6.564464e+05  3.963512e+05  0.226579  0.152931   \n",
       "2    UNG     250      11.320  5.708852e+06  4.604550e+06  0.722811  0.622602   \n",
       "3   SPCE     250       3.080  7.050816e+05  5.257106e+05  0.648899  0.805177   \n",
       "4   FCEL     250       7.520  6.941155e+05  7.997527e+05  1.146521  1.039477   \n",
       "5   SITC     250       6.500  5.111240e+05  5.012912e+05  0.190387  0.243997   \n",
       "6   PTLO     250       5.200  5.536657e+05  6.115804e+05  0.490735  0.505632   \n",
       "7     RC     250       2.075  5.153672e+05  4.319559e+05  0.419840  0.500689   \n",
       "8   ISSC     250      19.310  5.406963e+05  2.828315e+05  1.197928  0.808118   \n",
       "9     FC     250      19.375  4.250869e+05  3.060991e+05  0.328294  0.479614   \n",
       "\n",
       "   pct_big_moves_60d  max_dd_120d liq_ok hf_ok  data_ok     score  \n",
       "0           0.016667    -0.759868   True  True     True -0.838578  \n",
       "1           0.000000    -0.059595   True  True     True -1.128960  \n",
       "2           0.000000    -0.364580   True  True     True -1.140016  \n",
       "3           0.016667    -0.344156   True  True     True -1.164550  \n",
       "4           0.033333    -0.475503   True  True     True -1.363545  \n",
       "5           0.000000    -0.183844   True  True     True -1.410251  \n",
       "6           0.000000    -0.575686   True  True     True -1.428263  \n",
       "7           0.000000    -0.536501   True  True     True -1.490148  \n",
       "8           0.033333    -0.578105   True  True     True -1.523297  \n",
       "9           0.000000    -0.304369   True  True     True -1.624701  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 178 CIK data...\n",
      "Processed 1 / 178\n",
      "Processed 2 / 178\n",
      "Processed 3 / 178\n",
      "Processed 4 / 178\n",
      "Processed 5 / 178\n",
      "Processed 6 / 178\n",
      "Processed 7 / 178\n",
      "Processed 8 / 178\n",
      "Processed 9 / 178\n",
      "Processed 10 / 178\n",
      "Processed 11 / 178\n",
      "Processed 12 / 178\n",
      "Processed 13 / 178\n",
      "Processed 14 / 178\n",
      "Processed 15 / 178\n",
      "Processed 16 / 178\n",
      "Processed 17 / 178\n",
      "Processed 18 / 178\n",
      "Processed 19 / 178\n",
      "Processed 20 / 178\n",
      "Processed 21 / 178\n",
      "Processed 22 / 178\n",
      "Processed 23 / 178\n",
      "Processed 24 / 178\n",
      "Error fetching data for CIK 0001388141 (EDD): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0001388141.json\n",
      "Processed 25 / 178\n",
      "Processed 26 / 178\n",
      "Error fetching data for CIK 0000910068 (HIO): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0000910068.json\n",
      "Processed 27 / 178\n",
      "Processed 28 / 178\n",
      "Processed 29 / 178\n",
      "Processed 30 / 178\n",
      "Processed 31 / 178\n",
      "Processed 32 / 178\n",
      "Processed 33 / 178\n",
      "Processed 34 / 178\n",
      "Processed 35 / 178\n",
      "Processed 36 / 178\n",
      "Processed 37 / 178\n",
      "Processed 38 / 178\n",
      "Processed 39 / 178\n",
      "Processed 40 / 178\n",
      "Processed 41 / 178\n",
      "Processed 42 / 178\n",
      "Processed 43 / 178\n",
      "Processed 44 / 178\n",
      "Processed 45 / 178\n",
      "Processed 46 / 178\n",
      "Processed 47 / 178\n",
      "Processed 48 / 178\n",
      "Processed 49 / 178\n",
      "Error fetching data for CIK 0002053033 (PLTS): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0002053033.json\n",
      "Processed 50 / 178\n",
      "Processed 51 / 178\n",
      "Processed 52 / 178\n",
      "Processed 53 / 178\n",
      "Processed 54 / 178\n",
      "Processed 55 / 178\n",
      "Error fetching data for CIK 0002058349 (EFTY): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0002058349.json\n",
      "Error fetching data for CIK 0001615905 (JGH): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0001615905.json\n",
      "Processed 56 / 178\n",
      "Processed 57 / 178\n",
      "Processed 58 / 178\n",
      "Processed 59 / 178\n",
      "Error fetching data for CIK 0000846676 (AEF): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0000846676.json\n",
      "Processed 60 / 178\n",
      "Processed 61 / 178\n",
      "Processed 62 / 178\n",
      "Processed 63 / 178\n",
      "Processed 64 / 178\n",
      "Processed 65 / 178\n",
      "Processed 66 / 178\n",
      "Processed 67 / 178\n",
      "Processed 68 / 178\n",
      "Processed 69 / 178\n",
      "Processed 70 / 178\n",
      "Processed 71 / 178\n",
      "Processed 72 / 178\n",
      "Processed 73 / 178\n",
      "Processed 74 / 178\n",
      "Error fetching data for CIK 0000809708 (EMF): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0000809708.json\n",
      "Processed 75 / 178\n",
      "Processed 76 / 178\n",
      "Processed 77 / 178\n",
      "Processed 78 / 178\n",
      "Processed 79 / 178\n",
      "Processed 80 / 178\n",
      "Processed 81 / 178\n",
      "Processed 82 / 178\n",
      "Processed 83 / 178\n",
      "Processed 84 / 178\n",
      "Processed 85 / 178\n",
      "Processed 86 / 178\n",
      "Processed 87 / 178\n",
      "Processed 88 / 178\n",
      "Processed 89 / 178\n",
      "Processed 90 / 178\n",
      "Processed 91 / 178\n",
      "Processed 92 / 178\n",
      "Processed 93 / 178\n",
      "Processed 94 / 178\n",
      "Processed 95 / 178\n",
      "Processed 96 / 178\n",
      "Processed 97 / 178\n",
      "Processed 98 / 178\n",
      "Processed 99 / 178\n",
      "Processed 100 / 178\n",
      "Processed 101 / 178\n",
      "Processed 102 / 178\n",
      "Processed 103 / 178\n",
      "Processed 104 / 178\n",
      "Processed 105 / 178\n",
      "Processed 106 / 178\n",
      "Processed 107 / 178\n",
      "Processed 108 / 178\n",
      "Processed 109 / 178\n",
      "Processed 110 / 178\n",
      "Processed 111 / 178\n",
      "Processed 112 / 178\n",
      "Processed 113 / 178\n",
      "Processed 114 / 178\n",
      "Processed 115 / 178\n",
      "Processed 116 / 178\n",
      "Processed 117 / 178\n",
      "Processed 118 / 178\n",
      "Processed 119 / 178\n",
      "Processed 120 / 178\n",
      "Processed 121 / 178\n",
      "Processed 122 / 178\n",
      "Processed 123 / 178\n",
      "Processed 124 / 178\n",
      "Processed 125 / 178\n",
      "Processed 126 / 178\n",
      "Processed 127 / 178\n",
      "Processed 128 / 178\n",
      "Processed 129 / 178\n",
      "Processed 130 / 178\n",
      "Processed 131 / 178\n",
      "Processed 132 / 178\n",
      "Processed 133 / 178\n",
      "Processed 134 / 178\n",
      "Processed 135 / 178\n",
      "Processed 136 / 178\n",
      "Processed 137 / 178\n",
      "Processed 138 / 178\n",
      "Processed 139 / 178\n",
      "Processed 140 / 178\n",
      "Processed 141 / 178\n",
      "Processed 142 / 178\n",
      "Processed 143 / 178\n",
      "Processed 144 / 178\n",
      "Processed 145 / 178\n",
      "Processed 146 / 178\n",
      "Processed 147 / 178\n",
      "Processed 148 / 178\n",
      "Processed 149 / 178\n",
      "Processed 150 / 178\n",
      "Processed 151 / 178\n",
      "Error fetching data for CIK 0002047190 (TCGL): 404 Client Error: Not Found for url: https://data.sec.gov/api/xbrl/companyfacts/CIK0002047190.json\n",
      "Processed 152 / 178\n",
      "Processed 153 / 178\n",
      "Processed 154 / 178\n",
      "Processed 155 / 178\n",
      "Processed 156 / 178\n",
      "Processed 157 / 178\n",
      "Processed 158 / 178\n",
      "Processed 159 / 178\n",
      "Processed 160 / 178\n",
      "Processed 161 / 178\n",
      "Processed 162 / 178\n",
      "Processed 163 / 178\n",
      "Processed 164 / 178\n",
      "Processed 165 / 178\n",
      "Processed 166 / 178\n",
      "Processed 167 / 178\n",
      "Processed 168 / 178\n",
      "Processed 169 / 178\n"
     ]
    }
   ],
   "source": [
    "def get_json(url: str, headers : dict):\n",
    "    r = requests.get(url, headers=headers, timeout = 30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "def extract_data(data: dict) -> dict:\n",
    "    def safe_get(path: list, default=None):\n",
    "        cur = data\n",
    "        for p in path:\n",
    "            if not isinstance(cur, dict) or p not in cur:\n",
    "                return default\n",
    "            cur = cur[p]\n",
    "        return cur\n",
    "\n",
    "    assets = []\n",
    "    for item in safe_get(['facts','us-gaap','Assets','units','USD'], []):\n",
    "        assets.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    liabilities = []\n",
    "    for item in safe_get(['facts','us-gaap','Liabilities','units','USD'], []):\n",
    "        liabilities.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    cash = []\n",
    "    for item in safe_get(['facts','us-gaap','CashAndCashEquivalentsAtCarryingValue','units','USD'], []):\n",
    "        cash.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    shares = []\n",
    "    for item in safe_get(['facts','dei','EntityCommonStockSharesOutstanding','units','shares'], []):\n",
    "        shares.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    net_income = []\n",
    "    for item in safe_get(\n",
    "        ['facts','us-gaap','NetIncomeLossAvailableToCommonStockholdersBasic','units','USD'],\n",
    "        []\n",
    "    ):\n",
    "        net_income.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    revenue = []\n",
    "    for item in safe_get(['facts','us-gaap','Revenues','units','USD'], []):\n",
    "        revenue.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    ebit = []\n",
    "    for item in safe_get(['facts','us-gaap','OperatingIncomeLoss','units','USD'], []):\n",
    "        ebit.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    operatingcashflow = []\n",
    "    for item in safe_get(\n",
    "        ['facts','us-gaap','NetCashProvidedByUsedInOperatingActivities','units','USD'],\n",
    "        []\n",
    "    ):\n",
    "        operatingcashflow.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    debt = []\n",
    "    for item in safe_get(['facts','us-gaap','LongTermDebt','units','USD'], []):\n",
    "        debt.append((item.get('end'), item.get('val')))\n",
    "\n",
    "    return {\n",
    "        \"assets\": assets,\n",
    "        \"liabilities\": liabilities,\n",
    "        \"cash\": cash,\n",
    "        \"shares\": shares,\n",
    "        \"net_income\": net_income,\n",
    "        \"revenue\": revenue,\n",
    "        \"ebit\": ebit,\n",
    "        \"operating_cash_flow\": operatingcashflow,\n",
    "        \"long_term_debt\": debt,\n",
    "    }\n",
    "\n",
    "def get_edgar(cik):\n",
    "    COMPANYFACTS_URL_TMPL = \"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    headers = {\"User-Agent\": \"leo@gmail.com\", \"Accept-Encoding\": \"gzip, deflate\"}\n",
    "    url = COMPANYFACTS_URL_TMPL.format(cik=cik)\n",
    "    r = requests.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def get_more_data(tickers):\n",
    "    SEC_TICKER_MAP_URL = \"https://www.sec.gov/files/company_tickers_exchange.json\"\n",
    "    headers = {\"User-Agent\": \"leo@gmail.com\", \"Accept-Encoding\": \"gzip, deflate\"}    \n",
    "    CIK= get_json(SEC_TICKER_MAP_URL, headers)\n",
    "    out = {}\n",
    "    print(f\"Processing {len(tickers)} CIK data...\")\n",
    "    CIK_data = CIK['data']\n",
    "    counter = 0\n",
    "    for item in CIK_data:\n",
    "        \n",
    "        if item[2].upper() in tickers:\n",
    "            CIK_code = str(item[0]).zfill(10) \n",
    "            try:\n",
    "                data = get_edgar(CIK_code)\n",
    "            except (requests.RequestException) as e:\n",
    "                print(f\"Error fetching data for CIK {CIK_code} ({item[2].upper()}): {e}\")\n",
    "                counter+=1\n",
    "                continue\n",
    "            extracted = extract_data(data)\n",
    "            out[item[2].upper()] = extracted\n",
    "            print(f\"Processed {len(out)+counter} / {len(tickers)}\")\n",
    "    \n",
    "\n",
    "    return out\n",
    "df = get_more_data(screen[\"symbol\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42ecea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def json_to_df(edgar_json: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for ticker, metrics in edgar_json.items():\n",
    "        row = {\"ticker\": ticker}\n",
    "\n",
    "        # helper: parse list of (end, val) safely\n",
    "        def _sorted_vals(key):\n",
    "            vals = metrics.get(key, [])\n",
    "            # keep only pairs with end and val\n",
    "            vals = [(d, v) for d, v in vals if d is not None and v is not None]\n",
    "            return sorted(vals, key=lambda x: x[0])\n",
    "\n",
    "        # helper: record_date = latest end date across selected keys\n",
    "        record_dates = []\n",
    "        for key in [\"assets\", \"liabilities\", \"cash\", \"shares\", \"long_term_debt\",\n",
    "                    \"revenue\", \"net_income\", \"ebit\", \"operating_cash_flow\"]:\n",
    "            vals = _sorted_vals(key)\n",
    "            if vals:\n",
    "                record_dates.append(vals[-1][0])\n",
    "        row[\"record_date\"] = max(record_dates) if record_dates else np.nan\n",
    "\n",
    "        # ---- STOCK METRICS: take latest ----\n",
    "        for key in [\"assets\", \"liabilities\", \"cash\", \"shares\", \"long_term_debt\"]:\n",
    "            vals = _sorted_vals(key)\n",
    "            row[key] = vals[-1][1] if vals else np.nan\n",
    "\n",
    "        # ---- FLOW METRICS: TTM if possible else latest ----\n",
    "        for key in [\"revenue\", \"net_income\", \"ebit\", \"operating_cash_flow\"]:\n",
    "            vals = _sorted_vals(key)\n",
    "            if len(vals) >= 4:\n",
    "                row[key] = sum(v for _, v in vals[-4:])\n",
    "            elif vals:\n",
    "                row[key] = vals[-1][1]\n",
    "            else:\n",
    "                row[key] = np.nan\n",
    "\n",
    "        # ---- YoY comparisons for 3 important flow metrics ----\n",
    "        # Simple: compare latest value vs a value ~1 year earlier (within a tolerance window)\n",
    "        def _yoy(key):\n",
    "            vals = _sorted_vals(key)\n",
    "            if len(vals) < 2:\n",
    "                return np.nan\n",
    "\n",
    "            # convert date strings to pandas datetime for comparisons\n",
    "            dfv = pd.DataFrame(vals, columns=[\"end\", \"val\"])\n",
    "            dfv[\"end\"] = pd.to_datetime(dfv[\"end\"], errors=\"coerce\")\n",
    "            dfv[\"val\"] = pd.to_numeric(dfv[\"val\"], errors=\"coerce\")\n",
    "            dfv = dfv.dropna(subset=[\"end\", \"val\"]).sort_values(\"end\")\n",
    "            if len(dfv) < 2:\n",
    "                return np.nan\n",
    "\n",
    "            latest_end = dfv[\"end\"].iloc[-1]\n",
    "            latest_val = dfv[\"val\"].iloc[-1]\n",
    "\n",
    "            # target ~1 year before\n",
    "            target = latest_end - pd.Timedelta(days=365)\n",
    "            dfv[\"diff_days\"] = (dfv[\"end\"] - target).abs().dt.days\n",
    "\n",
    "            # pick closest within a loose window (handles annual-only or irregular reporting)\n",
    "            candidate = dfv.iloc[:-1].sort_values(\"diff_days\").head(1)\n",
    "            if candidate.empty:\n",
    "                return np.nan\n",
    "            if candidate[\"diff_days\"].iloc[0] > 430:  # too far away\n",
    "                return np.nan\n",
    "\n",
    "            prev_val = candidate[\"val\"].iloc[0]\n",
    "            if prev_val == 0 or not np.isfinite(prev_val) or not np.isfinite(latest_val):\n",
    "                return np.nan\n",
    "\n",
    "            return (latest_val - prev_val) / abs(prev_val)\n",
    "\n",
    "        row[\"assets_yoy\"] = _yoy(\"assets\")\n",
    "        row[\"net_income_yoy\"] = _yoy(\"net_income\")\n",
    "        row[\"operating_cash_flow_yoy\"] = _yoy(\"operating_cash_flow\")\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "edgar_df = json_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f4df2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar_df.to_csv(\"lowcap_sec_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eefe2349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>record_date</th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>cash</th>\n",
       "      <th>shares</th>\n",
       "      <th>long_term_debt</th>\n",
       "      <th>revenue</th>\n",
       "      <th>net_income</th>\n",
       "      <th>ebit</th>\n",
       "      <th>operating_cash_flow</th>\n",
       "      <th>assets_yoy</th>\n",
       "      <th>net_income_yoy</th>\n",
       "      <th>operating_cash_flow_yoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTL</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>6.619470e+08</td>\n",
       "      <td>3.964950e+08</td>\n",
       "      <td>86124000.0</td>\n",
       "      <td>266143286.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.089100e+07</td>\n",
       "      <td>-442312000.0</td>\n",
       "      <td>-457373000.0</td>\n",
       "      <td>-646427000.0</td>\n",
       "      <td>-0.200054</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>-0.284596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEPG</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>1.900570e+08</td>\n",
       "      <td>2.691700e+07</td>\n",
       "      <td>142775000.0</td>\n",
       "      <td>68748224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-171746000.0</td>\n",
       "      <td>-217623000.0</td>\n",
       "      <td>0.116446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOI</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>1.636190e+08</td>\n",
       "      <td>1.758930e+08</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>98381340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101711000.0</td>\n",
       "      <td>-69563000.0</td>\n",
       "      <td>-43998000.0</td>\n",
       "      <td>-0.086861</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>0.094519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RCKT</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>3.680330e+08</td>\n",
       "      <td>5.436400e+07</td>\n",
       "      <td>75948000.0</td>\n",
       "      <td>108222228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-430089000.0</td>\n",
       "      <td>-446717000.0</td>\n",
       "      <td>-525442000.0</td>\n",
       "      <td>-0.065166</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.046737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ILPT</td>\n",
       "      <td>2025-10-24</td>\n",
       "      <td>5.218846e+09</td>\n",
       "      <td>4.305216e+09</td>\n",
       "      <td>83173000.0</td>\n",
       "      <td>66659235.0</td>\n",
       "      <td>4.196825e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-336484000.0</td>\n",
       "      <td>157028000.0</td>\n",
       "      <td>95608000.0</td>\n",
       "      <td>-0.043258</td>\n",
       "      <td>0.114066</td>\n",
       "      <td>2.402956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>OPAD</td>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>2.234610e+08</td>\n",
       "      <td>1.836090e+08</td>\n",
       "      <td>30959000.0</td>\n",
       "      <td>36859946.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067703e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-59901000.0</td>\n",
       "      <td>3318000.0</td>\n",
       "      <td>-0.339826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.314657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>IBIO</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>6.415500e+07</td>\n",
       "      <td>8.116000e+06</td>\n",
       "      <td>28111000.0</td>\n",
       "      <td>22487308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>-19318000.0</td>\n",
       "      <td>-35383000.0</td>\n",
       "      <td>-37323000.0</td>\n",
       "      <td>1.616756</td>\n",
       "      <td>-0.421409</td>\n",
       "      <td>-0.524899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>SOGP</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>7.143700e+07</td>\n",
       "      <td>4.207700e+07</td>\n",
       "      <td>60534000.0</td>\n",
       "      <td>987114810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.219591e+09</td>\n",
       "      <td>-34797000.0</td>\n",
       "      <td>-45162000.0</td>\n",
       "      <td>-6696000.0</td>\n",
       "      <td>-0.104799</td>\n",
       "      <td>0.465609</td>\n",
       "      <td>0.780130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>BDSX</td>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>8.872200e+07</td>\n",
       "      <td>9.044400e+07</td>\n",
       "      <td>16604000.0</td>\n",
       "      <td>7955685.0</td>\n",
       "      <td>5.001000e+07</td>\n",
       "      <td>1.395060e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-61531000.0</td>\n",
       "      <td>-96470000.0</td>\n",
       "      <td>-0.136467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>OSG</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>2.147890e+09</td>\n",
       "      <td>1.000469e+09</td>\n",
       "      <td>27520000.0</td>\n",
       "      <td>43812035.0</td>\n",
       "      <td>5.180000e+08</td>\n",
       "      <td>4.235950e+08</td>\n",
       "      <td>-536119000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702000.0</td>\n",
       "      <td>-0.767946</td>\n",
       "      <td>-3.094826</td>\n",
       "      <td>-1.675668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker record_date        assets   liabilities         cash       shares  \\\n",
       "0     AUTL  2025-11-11  6.619470e+08  3.964950e+08   86124000.0  266143286.0   \n",
       "1     PEPG  2025-11-05  1.900570e+08  2.691700e+07  142775000.0   68748224.0   \n",
       "2      TOI  2025-11-06  1.636190e+08  1.758930e+08     200000.0   98381340.0   \n",
       "3     RCKT  2025-10-31  3.680330e+08  5.436400e+07   75948000.0  108222228.0   \n",
       "4     ILPT  2025-10-24  5.218846e+09  4.305216e+09   83173000.0   66659235.0   \n",
       "..     ...         ...           ...           ...          ...          ...   \n",
       "164   OPAD  2025-10-27  2.234610e+08  1.836090e+08   30959000.0   36859946.0   \n",
       "165   IBIO  2025-11-10  6.415500e+07  8.116000e+06   28111000.0   22487308.0   \n",
       "166   SOGP  2025-02-28  7.143700e+07  4.207700e+07   60534000.0  987114810.0   \n",
       "167   BDSX  2025-10-28  8.872200e+07  9.044400e+07   16604000.0    7955685.0   \n",
       "168    OSG  2025-11-07  2.147890e+09  1.000469e+09   27520000.0   43812035.0   \n",
       "\n",
       "     long_term_debt       revenue   net_income         ebit  \\\n",
       "0               NaN  3.089100e+07 -442312000.0 -457373000.0   \n",
       "1               NaN           NaN          NaN -171746000.0   \n",
       "2               NaN           NaN -101711000.0  -69563000.0   \n",
       "3               NaN           NaN -430089000.0 -446717000.0   \n",
       "4      4.196825e+09           NaN -336484000.0  157028000.0   \n",
       "..              ...           ...          ...          ...   \n",
       "164             NaN  1.067703e+09          NaN  -59901000.0   \n",
       "165             NaN  1.500000e+05  -19318000.0  -35383000.0   \n",
       "166             NaN  1.219591e+09  -34797000.0  -45162000.0   \n",
       "167    5.001000e+07  1.395060e+08          NaN  -61531000.0   \n",
       "168    5.180000e+08  4.235950e+08 -536119000.0          NaN   \n",
       "\n",
       "     operating_cash_flow  assets_yoy  net_income_yoy  operating_cash_flow_yoy  \n",
       "0           -646427000.0   -0.200054        0.036251                -0.284596  \n",
       "1           -217623000.0    0.116446             NaN                -0.045996  \n",
       "2            -43998000.0   -0.086861       -0.041367                 0.094519  \n",
       "3           -525442000.0   -0.065166        0.245612                 0.046737  \n",
       "4             95608000.0   -0.043258        0.114066                 2.402956  \n",
       "..                   ...         ...             ...                      ...  \n",
       "164            3318000.0   -0.339826             NaN                 2.314657  \n",
       "165          -37323000.0    1.616756       -0.421409                -0.524899  \n",
       "166           -6696000.0   -0.104799        0.465609                 0.780130  \n",
       "167          -96470000.0   -0.136467             NaN                 0.460216  \n",
       "168            1702000.0   -0.767946       -3.094826                -1.675668  \n",
       "\n",
       "[169 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgar_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
